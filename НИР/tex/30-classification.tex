\chapter{Существующие решения}
\section{Алгоритм RANSAC}
Алгоритм RANdom SAmple Consensus (RANSAC), предложенный Фишлером и Боллес \cite{RANSAC}, представляет собой стабильный метод оценки параметров модели на основе случайных выборок устойчевый к зашумлённости исходных данных (большая доля выбросов).

Часто возникает задача обработки данных, в которой необходимо определить параметры модели, которая должна удовлетворять исходным данным. Все исходные данные можно разделить на два типа: хорошие точки, удовлетворяющие модели, «не-выбросы» или «инлаеры» (англ. inlier) и ложные точки, шумы — случайные включения в исходные данные, «выбросы» или «аутлаеры» (англ. outlier).

RANSAC -- это итерационный алгоритм, который пределагает решения, используя минимальный набор данных, необходимых для оценки базовых параметров модели. Как указали Фишлер и Боллес, в отличие от обычных методов выборки, которые используют как можно больше данных для получения начального решения, а затем приступают к сокращению выбросов, RANSAC использует наименьший возможный набор и продолжает расширять его совместимыми точками из исходных данных.

На вход алгоритма поступают: 

\begin{enumerate}
	\item набор исходных данных $X$;
	\item функция $M$, позволяющая вычислить параметры $\theta$ модели $P$ по набору данных из $n$ точек;
	\item функция оценки $E$ соответствия точек полученной модели;
	\item порог $t$ для функции оценки;
	\item количество итераций метода $k$.
\end{enumerate}

Весь алгоритм состоит из одного цикла, каждую итерацию которого можно логически разделить на два этапа.

Первый этап — выбор точек и подсчёт модели:

\begin{itemize}
	\item из множества исходных точек $X$ случайным образом выбираются n различных точек;
	\item на основе выбранных точек вычисляются параметры $\theta$ модели $P$ с помощью функции $M$, построенную модель принято называть гипотезой.
\end{itemize}

Второй этап — проверка гипотезы:

\begin{itemize}
	\item для каждой точки проверяется её соответствие данной гипотезе с помощью функции оценки $E$ и порога $t$;
	\item каждая точка помечается инлаером или выбросом;
	\item после проверки всех точек, проверяется, является ли гипотеза лучшей на данный момент, и если является, то она замещает предыдущую лучшую гипотезу.
\end{itemize}

В конце работы цикла оставляется последняя лучшая гипотеза.

Результатом работы метода являются:

\begin{enumerate}
	\item параметры $\theta$ модели $P$; 
	\item точки исходных данных, помеченные инлаерами или выбросами.
\end{enumerate} 

Значение параметра $t$ должно быть определено в зависимости от конкретных требований, зависящих от данных, в большинстве случаев, только после экспериментальных оценок. Количество итераций $k$ выбирается достаточно большим, чтобы гарантировать, что по крайней мере один из наборов случайных выборок не содержит выбросов. Определяется оно методом теоретической оценки. Пусть $p$ — вероятность того, что алгоритм RANSAC на некоторой итерации, выбирая $n$ точек, на основе которых строится модель, возьмёт для расчётов из исходного набора данных только инлаеры. В такой ситуации построенная по данным точкам модель, с большой вероятностью будет достаточно точной. Исходя из этого, мы можем использовать вероятность $p$ для оценки точности работы алгоритма. Пусть $\omega$ -- ероятность выбора одного инлаера из общего числа точек, то есть $\omega=I/T$ -- количество инлаеров, $T$ -- общее число точек. В большинстве случаев доля инлаеров $\omega$ неизвестна до начала выполнения алгоритма, но практически всегда можно дать некоторую грубую оценку. Вероятность независимого выбора n инлаеров из исходных данных, в таком случае равна $q = C^n_I/C^n_T=I!(T-n)!/(T!(I-n)!)$, а вероятность того, что хотя бы одна точка из набора выброс, то есть что будет построена некорректная модель -- $(1-q)$. Вероятность того, что за $k$ итераций алгоритм ни разу не выберет $n$ инлаеров -- $(1−q)^k$, такая ситуация означает, что точная модель не будет построена, а вероятноть этого события равна $(1−p)$. Таким образом

$1-p=(1-q)^k$

Выразим необходимое нам количество итераций $k$:

$\displaystyle k = \frac{log(1-p)}{log(1-q)}$

Преимуществом алгоритма RANSAC является его способность дать надёжную оценку параметров модели, то есть возможность оценить параметры модели с высокой точностью, даже если в исходном наборе данных присутствует значительное количество выбросов. 

Одним из недостатков метода RANSAC является отсутствие верхней границы времени, необходимого для вычисления параметров модели. Если использовать в качестве некоторой границы времени максимальное число итераций, полученное решение может быть не оптимальным, а также существует очень малая вероятность, что ни одна модель не будет соответствовать исходным данным. Точная модель может быть определена с некоторой вероятностью, которая становится больше, чем больше итераций, которые используются. Ещё одним недостатком метода RANSAC является то, что для выполнения алгоритма необходимо задать конкретное пороговое значение. Наконец методом RANSAC можно определить только одну модель для определённого набора данных. Как и для любого подхода, предназначенного для одной модели, существует следующая проблема: когда в исходных данных присутствуют две (или более) модели, RANSAC может не найти ни одну.

Алгоритм RANSAC часто используется в компьютерном зрении, например, для решения задачи сопоставления изображений и оценки фундаментальной матрицы для определения параметров расположения камеры.

\section{Алгоритм SIFT}
Масштабно-инвариантная трансформация признаков (англ. scale-invariant feature transform, SIFT) это алгоритм компьютерного зрения, используемый для выявления и описания локальных признаков в изображениях. Этот алгоритм был опубликован Дэвидом Лоу в 1999 году и усовершенствован в 2004 году.

Сначала в SIFT извлекаются ключевые точки объектов из набора контрольных изображений \cite{Sift} и запоминаются в базе данных. Объект распознаётся в новом изображении путём сравнивания каждого признака из нового изображения с признаками из базы данных и нахождения признаков-кандидатов на основе евклидова расстояния между векторами признаков. Из полного набора соответствий в новом изображении отбираются поднаборы ключевых точек, которые наиболее хорошо согласуются с объектом по его местоположению, масштабу и ориентации. Определение подходящих блоков признаков осуществляется быстро с помощью эффективной реализации хеш-таблицы обобщённого преобразования Хафа. Каждый блок из 3 или более признаков, согласующийся с объектом и его положением, подлежит дальнейшей подробной проверке соответствия модели, и резко отклоняющиеся блоки отбрасываются. Наконец, вычисляется вероятность, что определённый набор признаков говорит о присутствии объекта, что даёт информацию о точности совпадения и числе возможных промахов. Объекты, которые проходят все эти тесты, могут считаться правильными с высокой степенью уверенности \cite{Sift2}. 

Лоу разбивает алгоритм SIFT на следующие четыре шага:

\begin{itemize}
	\item выявление экстремумов масштабного пространства: поиск ключевых (в рамках алгоритма SIFT) точек;
	\item локализация ключевых точек: отбрасывание точек с низкой контрастностью или расположенных не вдоль ребёр;
	\item определение направления: присваивание одного или нескольких направлений для каждой ключевой точки на основе локальных направлений градиента изображения;
	\item дескрипторы ключевых точек: вычисление дескриптора для каждой ключевой точки.
\end{itemize}

Ниже перечислены некоторые применения данного алгоритма:

\begin{itemize}
	\item распознавание объектов;
	\item определение местоположения и отслеживание техники/роботов;
	\item объеденение изображений;
	\item моделирование 3D-сцен, распознавание и трассировка;
	\item распознавания действий человека;
	\item анализ человеческого мозга в трёхмерных изображениях Магнитно-резонансной томографии.
\end{itemize}